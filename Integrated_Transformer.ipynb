{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f8369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import argparse\n",
    "from typing import List, Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import torchonn as onn\n",
    "# from torchonn.models import ONNBaseModel\n",
    "# from torchonn.op.mzi_op import project_matrix_to_unitary\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.types import Device, _size\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchonn.layers import MZILinear\n",
    "# from torchonn.models import ONNBaseModel\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from configs.config import configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320dd3e",
   "metadata": {},
   "source": [
    "### Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb628e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)  # Use the current module's name\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "acc_example = 0.95  # Replace with your actual accuracy calculation\n",
    "logger.info(f\"Current accuracy: %{acc_example}\")  # Log as info\n",
    "# logger.debug(\"Current accuracy: %.2f\", accuracy)  # Log as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"config\", metavar=\"FILE\", help=\"config file\")\n",
    "# args = parser.parse_args(args=['configs/eeg_pt.yml'])\n",
    "# args.config\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config\", metavar=\"FILE\", help=\"config file\")\n",
    "# parser.add_argument('--run-dir', metavar='DIR', help='run directory')\n",
    "# parser.add_argument('--pdb', action='store_true', help='pdb')\n",
    "args = parser.parse_args(args=['configs/eeg_pt.yml'])\n",
    "args, opts = parser.parse_known_args()\n",
    "\n",
    "configs.load(args.config, recursive=True)\n",
    "configs.update(opts)\n",
    "\n",
    "# if torch.cuda.is_available() and int(configs.run.use_cuda):\n",
    "#     torch.cuda.set_device(configs.run.gpu_id)\n",
    "#     device = torch.device(\"cuda:\" + str(configs.run.gpu_id))\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# if int(configs.run.deterministic) == True:\n",
    "#     set_torch_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af440e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config_file\", metavar=\"FILE\", help=\"config file\")\n",
    "# parser.add_argument('--run-dir', metavar='DIR', help='run directory')\n",
    "# parser.add_argument('--pdb', action='store_true', help='pdb')\n",
    "args = parser.parse_args(args=['configs/eeg_torch.yml'])\n",
    "# args, opts = parser.parse_known_args()\n",
    "# f = 'configs/eeg_pt.yml'\n",
    "with open(args.config_file, 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9182994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'mnist',\n",
       "  'root': './data',\n",
       "  'num_workers': 2,\n",
       "  'img_height': 28,\n",
       "  'img_width': 28,\n",
       "  'in_channels': 1,\n",
       "  'num_classes': 10,\n",
       "  'transform': 'basic',\n",
       "  'shuffle': 0},\n",
       " 'criterion': {'name': 'ce'},\n",
       " 'optimizer': {'name': 'adamw', 'lr': 0.002, 'weight_decay': 0.0},\n",
       " 'scheduler': {'name': 'cosine', 'lr_gamma': 0.99, 'lr_min': 0},\n",
       " 'run': {'experiment': 'mnist_cnn_train',\n",
       "  'n_epochs': 200,\n",
       "  'batch_size': 32,\n",
       "  'use_cuda': 1,\n",
       "  'gpu_id': 0,\n",
       "  'deterministic': 1,\n",
       "  'random_state': 42,\n",
       "  'log_interval': 200},\n",
       " 'quantize': {'weight_bit': 32, 'input_bit': 32},\n",
       " 'noise': {'phase_noise_std': 0,\n",
       "  'gamma_noise_std': 0,\n",
       "  'crosstalk_factor': 0,\n",
       "  'random_state': 42},\n",
       " 'checkpoint': {'save_best_model_k': 3,\n",
       "  'checkpoint_dir': 'mnist/mzi_cnn/train',\n",
       "  'model_comment': '',\n",
       "  'resume': 0,\n",
       "  'restore_checkpoint': ''},\n",
       " 'model': {'name': 'MZI_CLASS_CNN',\n",
       "  'mode': 'usv',\n",
       "  'kernel_list': [64, 64],\n",
       "  'kernel_size_list': [3, 3],\n",
       "  'hidden_list': [],\n",
       "  'block_list': [8, 8, 8],\n",
       "  'stride_list': [1, 1],\n",
       "  'padding_list': [1, 1],\n",
       "  'dilation_list': [1, 1],\n",
       "  'pool_out_size': 5,\n",
       "  'decompose_alg': 'reck'},\n",
       " 'debug': {'verbose': 1}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bd691",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, data_dir, label_dir, transform=None):\n",
    "#         self.annotations = pd.read_csv(label_dir)\n",
    "        self.data_dir = data_dir   # './data/origin_csv/train'\n",
    "        self.transform = transform\n",
    "        self.files = os.listdir(self.data_dir)\n",
    "        self.annotations = pd.read_csv(label_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.data_dir, self.files[index])\n",
    "        data = pd.read_csv(data_path)\n",
    "        data = torch.tensor(data.values, dtype=torch.float32)\n",
    "        file_name = self.files[index]\n",
    "        \n",
    "        label = torch.tensor(int(label_dic[self.annotations.iloc[index,1]]))\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return (data.t(), label, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_dir = './data/train_label.csv'\n",
    "train_data_dir = './data/origin_csv/train/'\n",
    "\n",
    "eval_label_dir = './data/eval_label.csv'\n",
    "eval_data_dir = './data/origin_csv/eval/'\n",
    "\n",
    "label_dic = {'normal':0, 'abnormal':1}\n",
    "\n",
    "    \n",
    "# transform = transforms.Compose([\n",
    "#     transforms.MinMaxScaler(feature_range=(0, 1)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "train_dataset = customDataset(data_dir=train_data_dir, label_dir=train_label_dir)\n",
    "eval_dataset = customDataset(data_dir=eval_data_dir, label_dir=eval_label_dir)\n",
    "# combined_dataset = ConcatDataset([train_dataset, eval_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a157aec",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb856f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define operation in auto-encoder\n",
    "class Mat_mul(nn.Module):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "#         self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        self.weight = Parameter(torch.empty((in_features, out_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return input @ self.weight + self.bias\n",
    "#         return torch.mul(input, self.weight, self.bias)\n",
    "    \n",
    "### Define auto-encoder    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            Mat_mul(input_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            Mat_mul(int(input_size/2), hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            Mat_mul(hidden_size, input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            Mat_mul(int(input_size/2), input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "#         z = self.encoder_2(z)\n",
    "        x_hat = self.decoder(z)\n",
    "#         x_hat = self.decoder_2(x_hat)\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "### Define transformer_classifier\n",
    "class transformer_classifier(nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(transformer_classifier, self).__init__()\n",
    "        self.au = AutoEncoder(input_size=1000, hidden_size=256)  \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=4)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(input_size, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.transformer_encoder(x)\n",
    "        z = self.flatten(z)\n",
    "        y = self.linear(z)\n",
    "        return y\n",
    "    \n",
    "classifier = transformer_classifier(256*19, 2).to('cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "80"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
